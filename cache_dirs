#!/bin/bash
# Using '/bin/bash' instead of '/usr/bin/env bash' means process gets listed in ps and pstree as cache_dirs instead of bash cache_dirs

#Programmer notes
# Check with https://www.shellcheck.net/

####################################################################################
# cache_dirs
# A utility to attempt to keep directory entries in the linux
# buffer cache to allow disks to spin down and no need to spin-up
# simply to get a directory listing on an unRAID server.
#
# Version 1.0   Initial proof of concept using "ls -R"
# Version 1.1   Working version, using "ls -R" or "find -maxdepth"
# Version 1.2   Able to be used with or without presence of user-shares.
#               Removed "ls -R" as it was too easy to run out of ram. (ask me how I know)
#               Added -i include_dir to explicitly state cached directories
#               Added -v option, verbose statistics when run in foreground
#               Added -q option, to easily terminate a process run in the background
#               Added logging of command line parameters to syslog
# Version 1.3   Added -w option, to wait till array comes online before starting scan
#               of /mnt/disk* share folders.
#               Changed min-seconds delay between scans to 1 instead of 0.
#               Moved test of include/exclude directories to after array is on-line
#               Added logging of mis-spelled/missing include/exclude dirs to syslog
#               Added ability to have shell wildcard expansion in include/exclude names
# Version 1.4   Fix bug with argument order passed to find when using -d option
#               Fixed command submitted to "at" to use full path. Should not need to
#              set PATH variable in "go" script.
#               Added ability to also cache scan /mnt/user with -u option
# Version 1.4.1 Fixed version comment so it is actually a comment.
# Version 1.5   Added -V to print version number.
#               Added explicit cache of root directories on disks and cache drive
#               Modified "average" scan time statistic to be weighted average with a window
#               of recent samples.
#               Added -a args option to allow entry of args to commands after dir/file name
#                 example: cache_dirs -a "-ls" -d 3
#                 This will execute "find disk/share -ls -maxdepth 3"
# Version 1.6   - Fixed bug... if -q was used, and cache_dirs not currently running,
#               it started running in error. OOps... Added the missing "exit"
#               - Changed vfs_cache_pressure setting to be 1 instead of 0 by default.
#               - Added "-p cache_pressure" to allow experimentation with vfs_cache_pressure values
#                (If not specified, default value of 1 will be used)
#               - Made -noleaf the default behavior for the "find" command (use -a "" to disable).
#               - Added logic to force all disks "busy" by starting a process with each as their
#               current working directory.   This will prevent a user from seeing a frightening
#               Unformatted description if they attempt to stop the array.  A second "Stop" will
#               succeed (the scan is paused for 2 minutes, so it may be stopped cleanly)
#               - Added new -B option to revert to the old behaviour and not force disks busy if by
#               chance this new feature causes problems for some users.
#               - Allow min seconds to be equal to max seconds in loop delay range.
#               - Added run-time-logging, log name = /var/log/cache_dirs.log
# Version 1.6.1 - Fixed bug. Added missing /mnt/cache disk to scanned directories
# Version 1.6.2 - Added trap to clean up processes after kill signal when run in background
# Version 1.6.3 - Modified to deal with new un-mounting message in syslog in 4.5b7 to
#                 allow array shutdown to occur cleanly.
# Version 1.6.4 - Modified to suspend scan during time "mover" script is running to prevent
#                 DuplicateFile messages from occurring as file is being copied.
#               - Added -S option to NOT suspend scan during mover process.
#               - Added logic to re-invoke cache_dirs if array is stopped and then re-started
#                 by submitting command string to "at" to re-invoke in a minute.
#               - Added entry to "usage()" function for -B
# Version 1.6.5 - Fixed what I broke in looking for "mover" pid to suspend during the "mover"
#                 to eliminate warnings in syslog about duplicate files detected while files were
#                 being copied.
# Version 1.6.6 - Fixed mover-detection to use the exact same logic as "mover" (and fixed stupid typo I had made)
# Version 1.6.7 - Added cache_pressure to "usage" statement, fixed bug where it reverted to 10 after being invoked through "at"
#                 when used with the -w option.
# Version 1.6.8 - Added -U NNNNN option to set ulimit, and detection of 64 bit OS so odds are this new option will not be needed.
#                 by default, ulimit is set to 5000 on 32 bit OS, and 30000 on 64 bit OS.  Either can be over-ridden with -U NNNNN on command line
# Version 1.6.9 - Removed exec of /bin/bash.  Newer bash was not setting SHELL variable causng infinate loop if invoked from "go" script.
#                 Changed default ulimit on 64 bit systems to 50000.
#                 by default, ulimit is now set to 5000 on 32 bit OS, and 50000 on 64 bit OS.  Either can be over-ridden with -U NNNNN on command line
#                 Setting ulimit to zero ( with "-U 0" option) is now special, cache_dirs will not set any ulimit at all.  You'll inherit the system value, whatever it might be.
# Joe L.
#
# Version 2.0.0 - Added gradual depth to avoid continous scans of filesystem, monitor of disk-idle, and better user-feedback as to disk spin-up in log-file.
#                 Now stops cache_dirs immediately on stop signal (eg array stop) including stopping the currently running find-process.
#                 Force-disk-busy now defaults no and inverted flag (and changed -B to -b) because it was (mostly) unRaid 4 and its unnessary when using plg with unmount disk event.
# Version 2.0.1 - Fixed missing sleep. Now decreases scan-depth after few seconds (20-40s) if cache is lost after many successful cache-hits, because we don't want cache_dirs to be a resource-hog when system is otherwise occupied.
# Version 2.0.2 - Fixed looping bash check in unRaid 6, plus fixed some too aggressive depth checks.
# Version 2.0.3 - Bugfix suspend mover, and added concise log of lost cache.
# Version 2.0.4 - Added more lost cache log, enabled by creating log file /var/log/cache_dirs_lost_cache.log
# Version 2.0.5 - Updated for unRaid 6.1.2 new location of mdcmd (used to find idle-times of disks)
# Version 2.0.6 - Included original 'B' option, it is unused but kept for compatibility reasons
#
# arberg
#
# Version 2.1.0 - Modified for unRaid V6.1 and above only.
#				- Removed V5 specific code.
#				- Removed disks busy code.
#				- Removed wait for array to come on line.
#				- Remove unused variables.
#				- Modifications to improve readability.
#
# Version 2.1.1	- Removed additional unused variables.
#				- Removed V5 ulimit usage info that doesn't apply.
#				- Show type of scanning being done - adaptive or fixed when cache_dirs is started.
# dlandon
#
# Version 2.2.0 - When cache lost, don't wait for disks idle, instead decrease depth
#               - Now scans each disks and cache in separate processes. Thus removed option -u for scan user
#               - Fixed loss of adaptive after 1 week
#               - Weekly rescan only when disks been idle long
#               - Apaptive scan will not retry increasing level to previous seen stable level until disks have been idle for a long time (20s)
#               - -q now also kills subproccesses immediately (so cache_dirs does not prevent stopping the array)
#               - Added file-count and depth adjustment by filecount
# arberg
####################################################################################
version=2.2.0
program_name=$(basename "$0")
arg_count=$#

run_log="/var/log/cache_dirs.log"
lost_cache_log="/var/log/cache_dirs_lost_cache.csv"

usage() {
	echo
	echo "Usage: $program_name [-m min_seconds] [-M max_seconds] [-F] [-d maxdepth(adaptive)] [-D maxdepth(fixed)] [-c command] [-a args] [-e exclude_dir] [-i include_dir]"
	echo "       $program_name -V      = print program version"
	echo "       $program_name -q"
	echo "       $program_name -l on   = turn on logging to $run_log and $lost_cache_log"
	echo "       $program_name -l off  = turn off logging to $run_log and $lost_cache_log"
	echo " -m NN    =   minimum seconds to wait between directory scans (default=1)"
	echo " -M NN    =   maximum seconds to wait between directory scans (default=10)"
	echo " -U NN    =   set ulimit to NN to limit memory used by script (default=50000), '-U 0' sets no ulimit at all)"
	echo " -F       =   do NOT run in background, run in Foreground and print statistics as it loops and scans"
	echo " -v       =   when used with -F, verbose statistics are printed as directories are scanned"
	echo " -s       =   shorter-log - print count of directories scanned to syslog instead of their names"
	echo " -d NN    =   max depth to allow when searching adaptively for appropriate depth level, used in \"find -maxdepth NN\" "
	echo " -D NN    =   sets fixed depth level and disables adaptive depth level, uses \"find -maxdepth NN\" "
	echo " -t NN    =   time in seconds between scheduled scan towards max depth, default weekly; this setting is only relevant with adaptive scan enabled (without -D setting)"
	echo " -W NN    =   Disk Idle Timer - When the disks have been idle this long, cache_dirs adaptive scan starts working towards building the cache."
	echo " -X NN    =   timeout in seconds for direcotry scan during disk-idle periods (and when fixed depth -D is set)"
	echo " -Y NN    =   timeout in seconds for direcotry scan during initial scan and when cache has been lost"
	echo " -Z NN    =   timeout in seconds for direcotry scan after all directories have been cached"
	echo " -c command = use command instead of \"find\" "
	echo "              (\"command\" should be quoted if it has embedded spaces)"
	echo " -a args  =   append args to command"
	echo " -e exclude_dir  (may be repeated as many times as desired)"
	echo " -i include_dir  (may be repeated as many times as desired)"
	echo " -p NN    =   set cache_pressure to NN (by default = 10). 0 means never reclaim cache. See 'vfs_cache_pressure' in https://www.kernel.org/doc/Documentation/sysctl/vm.txt"
	echo " -S       =   do not suspend scan during 'mover' process"
	echo " -z       =   concise log (log run criteria on one line)"
	echo " -q       =   terminate any background instance of cache_dirs"
}

background=yes
verbose=no
# min scan seconds ignored, always sleep max, because it always tended towards min_seconds anyway and seems unnecessary
min_seconds=1
max_seconds=10
short_log=no
maxDepthUnbounded=9999
maxDepth="$maxDepthUnbounded"
fixdepth=-1
command="find"
window_array_length=20
avg_elapsed_time=0
exclude_array_count=0
include_array_count=0
quit_flag="no"
suspend_during_mover="yes"
commandargs=$*
args="-noleaf"
concise_log="no"
# When min_disk_idle_before_restarting_scan_sec was 4 it restarting scanning too soon
min_disk_idle_before_restarting_scan_sec=60
# scan_timeout_sec_stable used for busy rescan and stable scan, scan_timeout_sec_idle used for initial on disks idle scan
scan_timeout_sec_busy=30
scan_timeout_sec_idle=150
scan_timeout_sec_stable=30
slow_scan_time_limit=15
# Adaptively increase depth by 1 until depth_max_incremental_depth, then go to $maxDepth
depth_max_incremental_depth=20
frequency_of_full_depth_scan_sec=$((7*24*3600))
MODE_IDLE_RESCANNING=1
MODE_BUSY_RESCANNING=2
MODE_STABLE=3
MODE_STABLE_IDLE=4
mode=$MODE_BUSY_RESCANNING
no_idle_scans_increase_depth=3
no_busy_scans_increase_depth=50
# Note that we decrease depth immediately if a scan has a timeout. A slow scan means its lasts longer than slow_scan_time_limit=15
no_slow_scans_decrease_depth_idle=4
no_slow_scans_decrease_depth_busy=4
no_slow_scans_decrease_depth_stable=4
min_no_scans_at_new_level=3

ulimit_mem=50000

# Constants
NANO_PR_SEC=1000000000

# cache_pressure of 0 will potentially run out of RAM if a large directory is scanned and not enough RAM
# esists. User processes will then be killed to free space rather than cache freed.
# (It has happened several times on my server when I forgot to exclude my data folder.
# It is not fun trying to regain control without a full reboot.  I've changed the default to "1" instead. )
# If you have enough RAM, and few enough files being cached, you can specify "-p 0" on the command line
# to set the vfs_cache_pressure to 0.  Otherwise, this default value of 1 should prevent memory starvation
# and the OOM (out-of-memory) state killing on your processes to free up some RAM.
# 1 did not do it with my 500Meg of RAM... trying cache_pressure of 10, use -p 1 if you still want the old value
cache_pressure=10

verbose_echo() {
	[ $background = "no" ] && [ $verbose = "yes" ] && echo "$1"
}

log() {
	[ $background = "no" ] && [ $verbose = "yes" ] && echo "$*"
	[ "$run_log" != "" ] && [ -f "$run_log" ] && echo "$*" >> $run_log
}

logLostCache() {
	if [ "$lost_cache_log" != "" ] && [ -f "$lost_cache_log" ] ; then
		first=1
		for var in "$@"
		do
			if ((first == 0)) ; then
				echo -n ' '
			fi
			echo -n "\"$var\""
			first=0
		done >> $lost_cache_log
		echo >> $lost_cache_log
	fi
}
logLostCacheSimple() {
	logLostCache $start_time_txt ${elapsed_secs} ${prev_sleep_duration} ${time_since_disk_access_before_scan_sec} $appliedDepth $appliedMaxDepthCurrent $appliedMaxDepth $1 $depth_slow_scan_counter $depth_success_idle_incr_counter
}

logLostCacheHeader() {
	if [ "$lost_cache_log" != "" ] && [ -f "$lost_cache_log" ] ; then
		echo '"Date" "Time" "ScanTime" "PrevSleep" "IdleTimeBeforeScan" "Depth" "MaxDepthCurrent" "MaxDepthWeek" "ForcedRestartDepthScan" "Scans at depth" "Scans succes count"' >> $lost_cache_log
	fi
}

syslog() {
	[ $background = "no" ] && echo "$1"
	[ "$run_log" != "" ] && [ -f "$run_log" ] && echo "$1" >> $run_log
	echo "$1" | logger "-t$program_name"
}

while getopts "p:m:M:c:d:D:e:i:l:FszBbwuvVahqSU:t:W:X:Y:Z:" opt; do
	case $opt in
	m ) min_seconds=$OPTARG ;;
	M ) max_seconds=$OPTARG ;;
	F ) background=no ;;
	v ) verbose=yes ;;
	V ) echo "$program_name version: $version"; exit 0 ;;
	u ) ;; # unused, kept for compatibility reasons
	c ) command="$OPTARG" ;;
	a ) args="$OPTARG" ;;
	d ) maxDepth=$OPTARG
		(( maxDepth <= depth_max_incremental_depth )) && depth_max_incremental_depth=$((maxDepth - 1))
		(( depth_max_incremental_depth == 0 )) && depth_max_incremental_depth=1
		command="find" ;;
	D ) fixdepth=$OPTARG
		command="find" ;;
	i ) include_array[$include_array_count]="$OPTARG"
		include_array_count=$((include_array_count+1)) ;;
	e ) exclude_array[$exclude_array_count]="$OPTARG"
		exclude_array_count=$((exclude_array_count+1)) ;;
	h ) usage >&2 ; exit 0 ;;
	p ) cache_pressure="$OPTARG" ;;
	U ) ulimit_mem="$OPTARG" ;;
	q ) quit_flag="yes" ;;
	w ) ;; # unused, kept for compatibility reasons
	s ) short_log="yes" ;;
	B ) ;; # unused, kept for compatibility reasons
	b ) ;; # unused, kept for compatibility reasons
	S ) suspend_during_mover="no" ;;
	z ) concise_log="yes" ;;
	t ) frequency_of_full_depth_scan_sec="$OPTARG" ;;
	l ) 
		case "$OPTARG" in
		on)
			touch $run_log
			touch $lost_cache_log
			echo "Logging enabled to $run_log and $lost_cache_log"
			;;
		off)
			rm "$run_log"
			rm "$lost_cache_log"
			echo "Logging to $run_log stopped"
			;;
		*)
			echo "Invalid argument to -l option"
			echo "Usage:" >&2
			echo "cache_dirs -l on" >&2
			echo "or" >&2
			echo "cache_dirs -l off" >&2
			exit 2
			;;
		esac
		;;
	W) min_disk_idle_before_restarting_scan_sec="$OPTARG" ;;
	X) scan_timeout_sec_idle="$OPTARG" ;;
	Y) scan_timeout_sec_busy="$OPTARG" ;;
	Z) scan_timeout_sec_stable="$OPTARG" ;;
	\?) usage >&2 ; exit ;;
	esac
done

if [ "$(whoami)" != "root" ]
then
	echo "ERROR: Run as root"
	exit 1
fi

# We need to use it with -KILL
killtree() {
    local _pid=$1
    local _sig=${2:--TERM}
    kill -stop ${_pid} # needed to stop quickly forking parent from producing children between child killing and parent killing
    for _child in $(ps -o pid --no-headers --ppid ${_pid}); do
        killtree ${_child} ${_sig}
    done
    kill ${_sig} ${_pid}
}

lockfile="/var/lock/cache_dirs.LCK"
if [ -f "${lockfile}" ] ; then
	# The file exists so read the PID
	# to see if it is still running
	lock_pid=$(head -n 1 "${lockfile}")

	pid_running=$(ps -p "${lock_pid}" | grep ${lock_pid})

	if [ -z "${pid_running}" ] ; then
		if [ "$quit_flag" = "no" ] ; then
			# The process is not running
			# Echo current PID into lock file
			echo $$ > "${lockfile}"
		else
			echo "$program_name ${lock_pid} is not currently running "
			rm "${lockfile}"
			exit 0
		fi
	else
		if [ "$quit_flag" = "yes" ] ; then
			syslog "Stopping $program_name process $lock_pid"
			# 1. Remove lock-file so we don't spawn new find-processes
			rm "${lockfile}"
			killtree "$lock_pid" -KILL
			exit 0
		else
			echo "$program_name is already running [${lock_pid}]"
			exit 2
		fi
	fi
else
	if [ "$quit_flag" = "yes" ] ; then
		echo "$program_name not currently running "
		exit 0
	else
		echo $$ > "${lockfile}"
	fi
fi

log "$program_name version $version"
#Try to play nice
if [ "$ulimit_mem" -gt 0 ] ; then
	log "Setting Memory ulimit to $ulimit_mem"
	ulimit -v "$ulimit_mem"
else
	log "No Memory ulimit applied"
fi
log "Setting maxdepth=$maxDepth"

# validate the cache pressure
cc="$(echo $cache_pressure | sed 's/[0-9]//g')"
if [ ! -z "$cc" ] ; then
	echo "error: cache_pressure must be numeric." >&2
	usage >&2
	exit 2
fi

# validate the min number of seconds
cc="$(echo $min_seconds | sed 's/[0-9]//g')"
if [ ! -z "$cc" ] ; then
	echo "error: min number of seconds must be numeric (whole number, not negative)." >&2
	usage >&2
	exit 2
fi

# validate the max number of seconds
cc="$(echo $max_seconds | sed 's/[0-9]//g')"
if [ ! -z "$cc" ] ; then
	echo "error: max number of seconds must be numeric." >&2
	usage >&2
	exit 2
fi
if [ $max_seconds -lt $min_seconds ] ; then
	echo "error: max number of seconds must be greater than or equal min number of seconds." >&2
	usage >&2
	exit 2
fi

# validate the maxDepth
cc="$(echo $maxDepth | sed 's/[0-9]//g')"
if [ ! -z "$cc" ] ; then
	echo "error: directory scan maxdepth must be numeric." >&2
	usage >&2
	exit 2
fi
cc="$(echo $frequency_of_full_depth_scan_sec | sed 's/[0-9]//g')"
if [ ! -z "$cc" ] ; then
	echo "error: scheduled rescan time must be numeric, with -t $frequency_of_full_depth_scan_sec" >&2
	usage >&2
	exit 2
fi

shift $((OPTIND - 1))

# start out in the middle of the range allowed
#num_seconds=$((( $max_seconds + $min_seconds ) / 2 ))
num_seconds=$max_seconds

log "Setting cache_pressure=$cache_pressure"
sysctl vm.vfs_cache_pressure=$cache_pressure >/dev/null 2>&1

# use function like this: result=$(fnc_time_since_last_disk_access)
fnc_time_since_last_disk_access() {
	# check if array is mounted by checking for disk1 directory
	if [ -d /mnt/disk1 ] ; then
		mdcmd_cmd=/usr/local/sbin/mdcmd

		# rdevLastIO will be non-zero if a disk is spinning, it will be the timestamp of last IO (in seconds since epoch)
		last=$($mdcmd_cmd status | grep -a rdevLastIO | grep -v '=0')
		echo "$(echo $last | awk '{t=systime(); gsub("rdevLastIO..=",""); for(i = 1; i <= NF; i++) a[++y]=$i}END{c=asort(a); if (NF > 0) print t-a[NF]; else print 9999; }')"
		# Code to log all disk ages
		# ages=$(echo $last | awk '{ t=systime(); for(i = 1; i <= NF; i++){ match($i, /rdevLastIO.([0-9]+)/, capgroups); gsub("rdevLastIO..=","", $i);  print capgroups[1] "=" t-$i } }') #print "diskage" i "=" t-$i
		# log "Ages: $ages"
	else
		# Array is not started
		echo "9999"
	fi
}

depthMinusOne() {
	depth=$1
	if (( depth == 1 )) ; then
		echo 1
	elif (( depth == maxDepth)) ; then
		echo "$depth_max_incremental_depth"
	else
		echo $(( depth - 1 ))
	fi
}

depthMinusPercent() {
	depth="$1"
	percent="$2"
	if (( percent <=0 || percent >= 100 )); then
		log "error percent $percent"
		percent=20
	fi
	local filesAtDepth="${files_at_depth_map[$depth]}"
	local depth_minus_one_value
	depth_minus_one_value=$(depthMinusOne "$depth")
	local result=1
	for ((i=depth_minus_one_value; i > 1; i--)) ; do
		# bash need $ on $appliedDepth inside hashmap inside (())
		if (( files_at_depth_map[$i] <= filesAtDepth*(100-percent)/100 )); then
			result=$i
			break;
		fi
	done
	echo "$result"
}

depthMinus20Percent() {
	echo "$(depthMinusPercent $1 20)"
}

depthMinus50Percent() {
	echo "$(depthMinusPercent $1 50)"
}


depthPlusOne() {
	depth=$1
	if (( depth == depth_max_incremental_depth || depth == maxDepth )) ; then
		echo "$maxDepth"
	else
		echo $(( depth + 1 ))
	fi
}

function join { local IFS="$1"; shift; echo "$*"; }

build_dir_list() {
	# build a list of directories to cache.
	#   If no "-i" options are given, this will be all the top level directories in /mnt/disk* and /mnt/cache
	#   If "-i" entries are given, they will be the only top level dirs cached.
	#   If "-e" (exclude) directories are given, they are then deleted from the list by the comm -23 coommand.
	if [ $include_array_count -gt 0 ] ; then
		top_dirs=`(
		# Include designated directories
		a=0
		while test $a -lt $include_array_count
		do
			included_excl=$(find /mnt/disk* /mnt/cache -type d -maxdepth 1 -mindepth 1 -name "${include_array[$a]}" -exec basename {} \; 2>/dev/null)
			echo "$included_excl" | sort -u
			a=$((a+1))
		done
		)| sort -u`
	else
		top_dirs=$(find /mnt/disk* /mnt/cache -type d -maxdepth 1 -mindepth 1  -exec basename {} \; 2>/dev/null | sort -u)
	fi

	exclude_dirs=`(
		# Exclude designated directories from being processed
		a=0
		while test $a -lt $exclude_array_count
		do
			expanded_excl=$(find /mnt/disk* /mnt/cache -type d -maxdepth 1 -mindepth 1 -name "${exclude_array[$a]}" -exec basename {} \; 2>/dev/null)
			echo "$expanded_excl" | sort -u
			a=$((a+1))
		done
	)| sort -u`
	scan_dirs=$(comm -23 <(echo "$top_dirs") <(echo "$exclude_dirs"))
	echo "$scan_dirs"
}


function wait_and_get_exit_codes() {
    children=("$@")
    LAST_EXIT_CODE=0
    for job in "${children[@]}"; do
       CODE=0;
       wait ${job} || CODE=$?
       if [[ "${CODE}" != "0" ]]; then
           LAST_EXIT_CODE=1;
       fi
   done
}

do_deep_scan() {
	depth_num=$1
	scan_timeout=$2
	depth_arg=""
	[ "$depth_num" -ne "$maxDepthUnbounded" ] && depth_arg="-maxdepth $depth_num"
	scanned_depth_msg+=" depth $depth_num"
	is_last_depth_scan_timed_out=0
	# will update dir_list on each scan, in case new shares have been added
	dir_list=$(build_dir_list)
	scan_start=$(date +%s%N)
	children_pids=()
	for i in /mnt/disk* /mnt/cache 
	do
		{
			for share_dir in $dir_list
			do
				dir_to_scan="$i/$share_dir"
				# if lockfile removed, then don't do new finds
				[ ! -f "$lockfile" ] && continue

				# If the directory does not exist on this disk, don't do recursive "directory scan"
				[ ! -d "$dir_to_scan" ] && continue

				current_time_nano=$(date +%s%N)
				# +1 to timeout because this is an integer computation
				remaining_time=$(( ((scan_timeout+1)*NANO_PR_SEC-(current_time_nano-scan_start) ) / NANO_PR_SEC ))
				# Debug logging
				# log "scanning $depth_num $dir_to_scan - remaining_time=$remaining_time - pid=$!"
				#verbose_echo "$start_time_txt Executing $command $i/$share_dir $args $depth_arg"
				if (( remaining_time > 0 )) ; then
					# Perform a recursive "find" on /mnt/disk??/share, or /mnt/user/share, or /mnt/cache/share
					if [ -f /bin/timeout ] ; then
						# Stop scan after n seconds. Should actually decrease wait-duration based on previous shares scan-time
						# Note timeout changes the pgid of its process, so cannot kill it using pgid
						/bin/timeout $remaining_time $command "$dir_to_scan" $args $depth_arg >/dev/null 2>&1
					else
						$command "$dir_to_scan" $args $depth_arg >/dev/null 2>&1
					fi
				fi
			done
		} &
		children_pids+=("$!")
	done
	wait_and_get_exit_codes "${children_pids[@]}"
	current_time_nano=$(date +%s%N)
	timepassed_total=$(( (current_time_nano - scan_start) ))
	#log "total: $timepassed_total / $scan_timeout"
	if [ $LAST_EXIT_CODE -ne 0 ] ; then
		is_last_depth_scan_timed_out=1
		scanned_depth_msg+="(timeout ${scan_timeout}s:Error=$LAST_EXIT_CODE)"
	elif (( timepassed_total >= scan_timeout * NANO_PR_SEC )) ; then
		is_last_depth_scan_timed_out=1
		scanned_depth_msg+="(timeout ${scan_timeout}s)"
	fi
}

# function: exists key in map
exists() {
  if [ "$2" != in ]; then
    echo 'Incorrect usage.'
    echo 'Correct usage: exists {key} in {array}'
    echo 'examlpe1:  if exists $i in files_at_depth_map; then echo "It exists" ; fi'
    echo 'examlpe1a: exists $i in files_at_depth_map && echo "It exists"'
    echo 'examlpe2: if ! exists $i in files_at_depth_map; then echo "Note there" ; fi'
    return
  fi   
  eval '[ ${'$3'[$1]+muahaha} ]'  
}

count_files() {
	local depth_arg=""
	[ "$1" -ne "$maxDepthUnbounded" ] && depth_arg="-maxdepth $1"
	totalCount=0 
	for i in /mnt/disk* /mnt/cache ; do
		for share_dir in $dir_list ; do
			dir_to_scan="$i/$share_dir"
			if [ -d "$dir_to_scan" ] ; then
				local thisDirCount=$(find $dir_to_scan -type f $depth_arg | wc -l)
				totalCount=$((totalCount+thisDirCount))
			fi
		done
	done 
	echo "$totalCount"
}

# does not work as function that echo result, missing cpu_last
# First cpu measurement will be wrong, missing last
update_cpu_usage() {
	cpu_now=($(head -n1 /proc/stat)) 
	# Get all columns but skip the first (which is the "cpu" string) 
	cpu_sum="${cpu_now[@]:1}" 
	# Replace the column seperator (space) with + 
	cpu_sum=$((${cpu_sum// /+})) 
	# Get the delta between two reads 
	cpu_delta=$((cpu_sum - cpu_last_sum)) 
	# Get the idle time Delta 
	cpu_idle=$((cpu_now[4]- cpu_last[4])) 
	# Calc time spent working 
	cpu_used=$((cpu_delta - cpu_idle)) 
	# Calc percentage 
	cpu_usage=$((100 * cpu_used / cpu_delta)) 

    # Keep this as last for our next read 
    cpu_last=("${cpu_now[@]}") 
    cpu_last_sum=$cpu_sum
}

format_two_digit() {
	echo "$(echo $1 | awk '{input=$1} END {printf "%2.0f", input}')"
}

# will update dir_list on each scan, in case new shares have been added
dir_list=$(build_dir_list)

if [ "$short_log" = "no" ] ; then
	log_list="$dir_list"
else
	log_list=$(echo "$dir_list" | wc -l)
	log_list=$(echo $log_list " directories cached")
fi

if ((fixdepth == -1)) ; then
	scan_type="adaptive"
	scan_depth=$maxDepth
else
	scan_type="fixed"
	scan_depth=$fixdepth
fi

if ((scan_depth == maxDepth)) ; then
	scan_depth="none"
fi

if [ "$concise_log" = "no" ] ; then
	echo "==============================================" | logger "-t$program_name"
	echo "Starting $program_name:" | logger "-t$program_name"
	echo "Arguments=$commandargs" | logger "-t$program_name"
	echo "Cache Pressure=$cache_pressure" | logger "-t$program_name"
	echo "Max Scan Secs=$max_seconds, Min Scan Secs=$min_seconds (min scan seconds ignored, always sleep max)" | logger "-t$program_name"
	echo "Scan Type=$scan_type" | logger "-t$program_name"
	echo "Max Scan Depth=$scan_depth" | logger "-t$program_name"
	echo "Use Command='$command $args'" | logger "-t$program_name"
	echo "Version=$version" | logger "-t$program_name"
	echo "---------- Caching Directories ---------------" | logger "-t$program_name"
	echo "$log_list" | logger "-t$program_name"
	echo "----------------------------------------------" | logger "-t$program_name"
else
	echo "Arguments=$commandargs, Version=$version, Cache Pressure=$cache_pressure, Max Scan Secs=$max_seconds, Min Scan Secs=$min_seconds, Scan Type=$scan_type, Max Depth=$scan_depth, Use Command='$command $args'" | paste -s -d "," - | logger "-t$program_name"
	echo "$log_list" | paste -s -d "," - | logger "-t$program_name"
fi
log "Setting Included dirs: $(join , ${include_array[@]})"
log "Setting Excluded dirs: $(join , ${exclude_array[@]})"
log "Currently monitored dirs: $(join , ${dir_list[@]})"
log "min_disk_idle_before_restarting_scan_sec=$min_disk_idle_before_restarting_scan_sec"
log "scan_timeout_sec_idle=$scan_timeout_sec_idle"
log "scan_timeout_sec_busy=$scan_timeout_sec_busy"
log "scan_timeout_sec_stable=$scan_timeout_sec_stable"
log "frequency_of_full_depth_scan_sec=$frequency_of_full_depth_scan_sec"
log "command-args=$commandargs"

logLostCacheHeader

a=0
while test $a -lt $exclude_array_count
do
	list=$(eval ls /mnt/disk*/"${exclude_array[$a]}" /mnt/cache/"${exclude_array[$a]}" 2>/dev/null)
	if [ "$list" = "" ] ; then
		echo "ERROR: excluded directory '${exclude_array[$a]}'' does not exist." >&2
		echo "ERROR: excluded directory '${exclude_array[$a]}' does not exist." | logger "-t$program_name"
	fi
	a=$((a+1))
done

a=0
while test $a -lt $include_array_count
do
	list=$(eval ls /mnt/disk*/"${include_array[$a]}" /mnt/cache/"${include_array[$a]}" 2>/dev/null)
	if [ "$list" = "" ] ; then
		echo "ERROR: included directory '${include_array[$a]}' does not exist." >&2
		echo "ERROR: included directory '${include_array[$a]}' does not exist." | logger "-t$program_name"
	fi
	a=$((a+1))
done

function get_scan_timeout() {
	if ((fixdepth >= 0)) ; then
		echo "${scan_timeout_sec_idle}"
	elif (( mode == MODE_IDLE_RESCANNING || mode == MODE_STABLE_IDLE )) ; then
		echo "${scan_timeout_sec_idle}"
	elif (( mode == MODE_BUSY_RESCANNING )) ; then
		echo "${scan_timeout_sec_busy}"
	elif (( mode == MODE_STABLE )) ; then
		echo "${scan_timeout_sec_stable}"
	else
		log "Error unknown mode '$mode'"
		echo "${scan_timeout_sec_stable}"
	fi
}

# Internal vars
# isPreviousMaxDepthComputed will be true(1) if we have reached the depth we currently think of as our max depth, ie. appliedDepth == appliedMaxDepth
# - appliedMaxDepth is computed once, and after that we always try to regain that depth, which would cause load on system, unless we wait for idle disks I suppose
depth_scan_counter=0
depth_success_idle_incr_counter=0
depth_success_busy_incr_counter=0
depth_slow_scan_counter=0
if ((fixdepth >= 0)) ; then
	appliedDepth=$fixdepth
	maxDepth=$fixdepth
	isPreviousMaxDepthComputed=1
	scan_timeout_sec=${scan_timeout_sec_idle}
else
	appliedDepth=1
	scan_timeout_sec=${scan_timeout_sec_busy}
	isPreviousMaxDepthComputed=0
fi

# invariant appliedMaxDepthCurrent < appliedMaxDepth <= maxDepth
# appliedMaxDepthCurrent: Current stable set, will be increased after long disk idle
# appliedMaxDepth: Best seen appliedMaxDepth, reset once a week
# maxDepth: User configured max depth
appliedMaxDepth=$maxDepth
appliedMaxDepthCurrent=$appliedMaxDepth
last_scan_towards_max_depth=$(date +%s)
is_last_depth_scan_timed_out=0
prev_sleep_duration=0
next_sleep_duration=0

declare -A files_at_depth_map

while [ -f "$lockfile" ]
do
	if [ "$suspend_during_mover" = "yes" ] ; then
		if [ -f /var/run/mover.pid ] ; then
			if ps h $(cat /var/run/mover.pid) | grep mover >/dev/null 2>&1 ; then
				log "Suspended during moving, now sleeping 10 seconds"
				sleep 10
				continue
			fi
		fi
	fi

	# always cache root dirs on each of the disks
	for i in /mnt/disk* /mnt/cache
	do
		find $i -maxdepth 1 -noleaf >/dev/null 2>/dev/null
	done

	time_since_disk_access_before_scan_sec=$(fnc_time_since_last_disk_access)
	if ((fixdepth == -1)) ; then
		(( time_since_disk_access_before_scan_sec >= min_disk_idle_before_restarting_scan_sec )) && hasBeenIdleLong=1 || hasBeenIdleLong=0
		if (( depth_scan_counter >= min_no_scans_at_new_level )) ; then
			# never change mode before having tried a few times to build cache pressure at level
			if (( hasBeenIdleLong )) ; then
				if (( mode == MODE_STABLE )) ; then
					mode=$MODE_STABLE_IDLE
				elif (( mode == MODE_BUSY_RESCANNING )) ; then
					mode=$MODE_IDLE_RESCANNING
				fi
			elif (( time_since_disk_access_before_scan_sec == 0 )) ; then
				if ((mode == MODE_IDLE_RESCANNING)) ; then
					# We have slept a second, so if disks have not been idle for a second, it means they are busy again. It does not hurt if we move back and forth between the two modes
					if (( appliedDepth <= 3 )) ; then
						mode=$MODE_BUSY_RESCANNING
					else
						# It seems to work great to do all scanning work when we know system is idle, and stop immediately with the scanning of deeper levels when disks are not idle.
						mode=$MODE_STABLE
					fi
				elif ((mode == MODE_STABLE_IDLE)) ; then
					# It seems to work great to do all scanning work when we know system is idle, and stop immediately with the scanning of deeper levels when disks are not idle.
					mode=$MODE_STABLE
				fi 
			fi
		fi	
	fi

	############## Here the actual find is executed ################
	start_time_nano=$(date +%s%N)
	start_time_txt=$(date "+%Y.%m.%d %H:%M:%S")

	scan_timeout_sec=$(get_scan_timeout)
	scanned_depth_msg=""
	# I tried rescan at lower depth if scan timed out, but it hurt cache, some depth levels were unattainable with the lower depth scan enabled, they must have evicted higher depth cache for some reason
	do_deep_scan $appliedDepth $scan_timeout_sec
	# Count number of files at depth, the first time depth is used
	if ! exists "$appliedDepth" in files_at_depth_map ; then
		files_at_depth_map[$appliedDepth]+="$(count_files $appliedDepth)"
		if ((appliedDepth == maxDepth)) ; then
			depth_max_incremental_depth=$(depthMinus20Percent $maxDepth)
			log "depth_max_incremental_depth=$depth_max_incremental_depth"
			# Debug logging of levels
			# log "depthMinus20Percent($maxDepth)=$(depthMinus20Percent $maxDepth)"
			# for ((i=1; i < 20; i++)) ; do
			# 	# bash need $ on $appliedDepth inside hashmap inside (())
			# 	log "depthMinus20Percent($i)=$(depthMinus20Percent $i)"
			# done
			# log "depthMinus50Percent($maxDepth)=$(depthMinus50Percent $maxDepth)"
			# for ((i=1; i < 20; i++)) ; do
			# 	# bash need $ on $appliedDepth inside hashmap inside (())
			# 	log "depthMinus50Percent($i)=$(depthMinus50Percent $i)"
			# done
		fi
	fi

	time_since_disk_access_after_scan_sec=$(fnc_time_since_last_disk_access)
	end_time_nano=$(date +%s%N)

	# track how long the recursive "directory scan" is taking.  If it starts to take longer it must be
	# because it has to read more from the physical disk.  If so, adjust the timing to
	# perform the directory scan more frequently.
	elapsed_time=$(( end_time_nano-start_time_nano ))
	elapsed_secs=$(( elapsed_time / NANO_PR_SEC ))
	were_disks_idle_during_scan=$((time_since_disk_access_after_scan_sec>=elapsed_secs))

	# Only update avg scan time when disks were idle during scan. This gives us ability to judge whether disks were accessed due to cache_dirs scan even if other processes access disks
	if (( were_disks_idle_during_scan )) ; then
		alen=${#avg[@]}
		# Move all the counts up one position in the array.
		for (( i = alen ; i > 0 ; i-- ))
		do
			[ $i -lt $window_array_length ] && avg[$((i+1))]=${avg[$i]}
		done

		# The newest will always be stored at index 1
		avg[1]=$elapsed_time

		# get the weighted average of the last $window_array_length loop passes
		# more recent values count far more than older values.
		tot_time=0
		alen=${#avg[@]}

		tot_count=0
		for (( i = 1; i <= alen; i++ ))
		do
			weight=$(( alen - i + 1 ))
			weight=$(( weight * 3 ))
			tot_count=$(( tot_count + weight))
			tot_time=$(( tot_time + avg[i] * weight ))
		done
		avg_elapsed_time=$((tot_time/tot_count))
	elif [ $avg_elapsed_time -eq 0 ] ; then
		avg_elapsed_time=$elapsed_time
	fi

	# Only decrease sleep when non-idle scan, note avg is computed over scan with idle disks, but not necessary at current depth level
	if (( !were_disks_idle_during_scan && avg_elapsed_time * 3 < elapsed_time && num_seconds > min_seconds )) ; then
		num_seconds=$min_seconds
	fi
	if (( avg_elapsed_time + NANO_PR_SEC > elapsed_time && num_seconds < max_seconds )) ; then
		num_seconds=$max_seconds
	fi

	is_slow_scan=0
	is_depth_reduced=0
	log_disk_access_msg=""

	current_time_sec=$(date +%s)
	skip_sleep=0
	if ((fixdepth == -1)) ; then
		# Judge last scan based on duration and timeout: Increment success or failure counters
		if ((were_disks_idle_during_scan)) ; then
			log_disk_access_msg="Idle____________"
			((depth_success_idle_incr_counter++))
			depth_slow_scan_counter=0
		elif (( elapsed_secs < slow_scan_time_limit )) ; then
			# Semi-INVARIANT: ! is_last_depth_scan_timed_out becasue probably slow_scan_time_limit < scan_timeout 
			# build cache-pressure by repeating successfull search, and give time for checking for disk-access
			if (( elapsed_time <= avg_elapsed_time + 2*NANO_PR_SEC )) ; then
				# depth_slow_scan_counter because we suspect its a scan which didn't access disks, since scan time was as fast as usual.
				depth_slow_scan_counter=0
				log_disk_access_msg="NonIdleFast_____"
			else
				log_disk_access_msg="NonIdleSlowerAvg"
			fi
			((depth_success_busy_incr_counter++))
		else
			log_disk_access_msg="NonIdleTooSlow__"
			is_slow_scan=1
			((depth_slow_scan_counter++))
			depth_success_idle_incr_counter=0
			depth_success_busy_incr_counter=0
			skip_sleep=1
		fi
	fi

	update_cpu_usage
	CPU="$(format_two_digit $cpu_usage)"
	# Note elapsed_secs is an integer, so we need to recompute it from elapsed_time in the awk command below
	avg_text=$(awk "BEGIN{ printf \"%05.2fs, wavg=%05.2fs\n\", ($elapsed_time/$NANO_PR_SEC), ($avg_elapsed_time/$NANO_PR_SEC) ; }")
	log "$start_time_txt Executed $command in (${elapsed_secs}s) $avg_text ${log_disk_access_msg} $scanned_depth_msg slept ${next_sleep_duration}s Disks idle before/after ${time_since_disk_access_before_scan_sec}s/${time_since_disk_access_after_scan_sec}s suc/fail cnt=$depth_scan_counter/$depth_success_idle_incr_counter/$depth_slow_scan_counter mode=$mode scan_tmo=${scan_timeout_sec}s maxCur=$appliedMaxDepthCurrent maxWeek=$appliedMaxDepth isMaxDepthComputed=$isPreviousMaxDepthComputed CPU=${CPU}%, filecount[$appliedDepth]=${files_at_depth_map[$appliedDepth]}"

	if ((fixdepth == -1)) ; then
		time_since_last_disk_access_sec=$(fnc_time_since_last_disk_access)
		(( time_since_last_disk_access_sec >= min_disk_idle_before_restarting_scan_sec )) && hasBeenIdleLong=1 || hasBeenIdleLong=0
		if (( mode == MODE_IDLE_RESCANNING)) ; then
			no_slow_scans_decrease_depth=$no_slow_scans_decrease_depth_idle
		elif (( mode == MODE_BUSY_RESCANNING)) ; then
			no_slow_scans_decrease_depth=$no_slow_scans_decrease_depth_busy
		else
			no_slow_scans_decrease_depth=$no_slow_scans_decrease_depth_stable
		fi
		((depth_scan_counter++))
		# appliedMaxDepthCurrent: Used when in mode MODE_BUSY_RESCANNING, and that mode is started when disks where idle during last scan. It has no effect in the other modes I believe.

		# Now increment or decrement depth level based on counters
		if (( mode != MODE_STABLE && (depth_success_idle_incr_counter >= no_idle_scans_increase_depth || depth_success_busy_incr_counter > no_busy_scans_increase_depth) || hasBeenIdleLong && depth_success_idle_incr_counter >= 1 )) ; then
			if (( appliedDepth == maxDepth )) ; then
				isPreviousMaxDepthComputed=1
			fi
			if (( appliedDepth < appliedMaxDepthCurrent || appliedDepth < appliedMaxDepth && (mode == MODE_IDLE_RESCANNING || mode == MODE_STABLE_IDLE) )) ; then
				# Increment depth and check depth_max_incremental_depth: skip straight to maxDepth if deep enough, so we can start sleeping
				appliedDepth=$(depthPlusOne $appliedDepth)
				depth_slow_scan_counter=0
				depth_success_idle_incr_counter=0
				depth_success_busy_incr_counter=0
				depth_scan_counter=0
				if (( hasBeenIdleLong && appliedDepth < appliedMaxDepth )) ; then	
					mode=$MODE_IDLE_RESCANNING
				fi
			elif (( (appliedDepth == appliedMaxDepthCurrent && mode == MODE_BUSY_RESCANNING) || appliedDepth == appliedMaxDepth )) ; then
				mode=$MODE_STABLE
			fi
		elif (( (appliedDepth > 0 && depth_slow_scan_counter >= no_slow_scans_decrease_depth || is_last_depth_scan_timed_out) && depth_scan_counter >= min_no_scans_at_new_level )) ; then
			# Sometimes it takes a few scans to build cache pressure which is seen by first scan being very slow, second a bit slow third pretty fast. So never decrease before trying at least 3 scans at level
			depth_slow_scan_counter=0
			depth_success_idle_incr_counter=0
			depth_success_busy_incr_counter=0
			#don't reset 'depth_scan_counter=0' because we are decreasing level
			# Reduce max-depth
			appliedMaxDepthCurrent=$(depthMinusOne "$appliedDepth")
			is_depth_reduced=1
			if (( mode == MODE_STABLE )) ; then			
				appliedDepth=$(depthMinus50Percent "$appliedDepth")
			else 
				appliedDepth=$(depthMinusOne "$appliedDepth")
				if (( !isPreviousMaxDepthComputed && (mode == MODE_IDLE_RESCANNING || mode == MODE_STABLE_IDLE) )) ; then
					# We were doing a scan during a time when disks have been idle, so system low was probably low. We take this to indicate this is the best depth the system can handle.
					# Set max depth ceiling, which will be rechecked weekly. Move to stable mode, at one level below current level.
					appliedMaxDepth=$appliedMaxDepthCurrent
					isPreviousMaxDepthComputed=1
				fi
				mode=$MODE_STABLE
			fi
		elif (( were_disks_idle_during_scan && (mode == MODE_STABLE || mode == MODE_STABLE_IDLE) && appliedDepth < appliedMaxDepthCurrent )) ; then
			mode=$MODE_BUSY_RESCANNING
		fi

		if (( appliedMaxDepthCurrent < appliedDepth )) ; then
			appliedMaxDepthCurrent="$appliedDepth"
		fi

		# Weekly full scan: In case of reduced max depth, test if we should reset and try going deeper again
		if (( current_time_sec > last_scan_towards_max_depth + frequency_of_full_depth_scan_sec && time_since_last_disk_access_sec >= min_disk_idle_before_restarting_scan_sec )) ; then
			last_scan_towards_max_depth=$current_time_sec
			if (( appliedMaxDepth < maxDepth )) ; then
				log "Starting scheduled depth scan again after waiting ${frequency_of_full_depth_scan_sec}s - disks have been idle for ${time_since_last_disk_access_sec}s"
				appliedMaxDepth=$maxDepth
				isPreviousMaxDepthComputed=0
				scan_timeout_sec=${scan_timeout_sec_idle}
			fi
		fi
		if (( is_depth_reduced )); then 
			logLostCacheSimple 1
		elif (( is_slow_scan )); then
			logLostCacheSimple 0
		fi	
	fi

	(( mode == MODE_STABLE && !is_last_depth_scan_timed_out )) && next_sleep_duration=$num_seconds || next_sleep_duration=1
	# we only skip sleep when scan is taking long, so it cannot significantly change impact whether or not we sleep 1 sec. We skip sleep to help cache pressure to build
	if ((!skip_sleep)) ; then
		sleep ${next_sleep_duration}
	fi
	prev_sleep_duration=$next_sleep_duration
done &

# while loop was put into background, now disown it
# so it will continue to run when you log off
# to get it to stop, type: rm /var/lock/cache_dirs.LCK

background_pid=$!
echo $background_pid > "${lockfile}"
if [ $background = "no" ] ; then
	# only way to get here is to remove the lock file or kill the background process shell with the while loop
	trap "rm -f $lockfile; killtree $background_pid -KILL 2>/dev/null; exit" INT TERM EXIT
	wait
else
	echo "$program_name process ID $background_pid started" >&2
	echo "$program_name process ID $background_pid started" | logger "-t$program_name"
	disown %%
fi
