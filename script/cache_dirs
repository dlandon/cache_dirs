#!/bin/bash

####################################################################################
# cache_dirs
# A utility to attempt to keep directory entries in the linux
# buffer cache to allow disks to spin down and no need to spin-up
# simply to get a directory listing on an unRAID server.
#
# Version 1.0   Initial proof of concept using "ls -R"
# Version 1.1   Working version, using "ls -R" or "find -maxdepth"
# Version 1.2   Able to be used with or without presence of user-shares.
#               Removed "ls -R" as it was too easy to run out of ram. (ask me how I know)
#               Added -i include_dir to explicitly state cached directories
#               Added -v option, verbose statistics when run in foreground
#               Added -q option, to easily terminate a process run in the background
#               Added logging of command line parameters to syslog
# Version 1.3   Added -w option, to wait till array comes online before starting scan
#               of /mnt/disk* share folders.
#               Changed min-seconds delay between scans to 1 instead of 0.
#               Moved test of include/exclude directories to after array is on-line
#               Added logging of mis-spelled/missing include/exclude dirs to syslog
#               Added ability to have shell wildcard expansion in include/exclude names
# Version 1.4   Fix bug with argument order passed to find when using -d option
#               Fixed command submitted to "at" to use full path. Should not need to
#              set PATH variable in "go" script.
#               Added ability to also cache scan /mnt/user with -u option
# Version 1.4.1 Fixed version comment so it is actually a comment.
# Version 1.5   Added -V to print version number.
#               Added explicit cache of root directories on disks and cache drive
#               Modified "average" scan time statistic to be weighted average with a window
#               of recent samples.
#               Added -a args option to allow entry of args to commands after dir/file name
#                 example: cache_dirs -a "-ls" -d 3
#                 This will execute "find disk/share -ls -maxdepth 3"
# Version 1.6   - Fixed bug... if -q was used, and cache_dirs not currently running,
#               it started running in error. OOps... Added the missing "exit"
#               - Changed vfs_cache_pressure setting to be 1 instead of 0 by default.
#               - Added "-p cache_pressure" to allow experimentation with vfs_cache_pressure values
#                (If not specified, default value of 1 will be used)
#               - Made -noleaf the default behavior for the "find" command (use -a "" to disable).
#               - Added logic to force all disks "busy" by starting a process with each as their
#               current working directory.   This will prevent a user from seeing a frightening
#               Unformatted description if they attempt to stop the array.  A second "Stop" will
#               succeed (the scan is paused for 2 minutes, so it may be stopped cleanly)
#               - Added new -B option to revert to the old behaviour and not force disks busy if by
#               chance this new feature causes problems for some users.
#               - Allow min seconds to be equal to max seconds in loop delay range.
#               - Added run-time-logging, log name = /var/log/cache_dirs.log
# Version 1.6.1 - Fixed bug. Added missing /mnt/cache disk to scanned directories
# Version 1.6.2 - Added trap to clean up processes after kill signal when run in background
# Version 1.6.3 - Modified to deal with new un-mounting message in syslog in 4.5b7 to
#                 allow array shutdown to occur cleanly.
# Version 1.6.4 - Modified to suspend scan during time "mover" script is running to prevent
#                 DuplicateFile messages from occurring as file is being copied.
#               - Added -S option to NOT suspend scan during mover process.
#               - Added logic to re-invoke cache_dirs if array is stopped and then re-started
#                 by submitting command string to "at" to re-invoke in a minute.
#               - Added entry to "usage()" function for -B
# Version 1.6.5 - Fixed what I broke in looking for "mover" pid to suspend during the "mover"
#                 to eliminate warnings in syslog about duplicate files detected while files were
#                 being copied.
# Version 1.6.6 - Fixed mover-detection to use the exact same logic as "mover" (and fixed stupid typo I had made)
# Version 1.6.7 - Added cache_pressure to "usage" statement, fixed bug where it reverted to 10 after being invoked through "at"
#                 when used with the -w option.
# Version 1.6.8 - Added -U NNNNN option to set ulimit, and detection of 64 bit OS so odds are this new option will not be needed.
#                 by default, ulimit is set to 5000 on 32 bit OS, and 30000 on 64 bit OS.  Either can be over-ridden with -U NNNNN on command line
# Version 1.6.9 - Removed exec of /bin/bash.  Newer bash was not setting SHELL variable causng infinate loop if invoked from "go" script.
#                 Changed default ulimit on 64 bit systems to 50000.
#                 by default, ulimit is now set to 5000 on 32 bit OS, and 50000 on 64 bit OS.  Either can be over-ridden with -U NNNNN on command line
#                 Setting ulimit to zero ( with "-U 0" option) is now special, cache_dirs will not set any ulimit at all.  You'll inherit the system value, whatever it might be.
# Joe L.
#
# Version 2.0.0 - Added gradual depth to avoid continous scans of filesystem, monitor of disk-idle, and better user-feedback as to disk spin-up in log-file.
#                 Now stops cache_dirs immediately on stop signal (eg array stop) including stopping the currently running find-process.
#                 Force-disk-busy now defaults no and inverted flag (and changed -B to -b) because it was (mostly) unRaid 4 and its unnessary when using plg with unmount disk event.
# Version 2.0.1 - Fixed missing sleep. Now decreases scan-depth after few seconds (20-40s) if cache is lost after many successful cache-hits, because we don't want cache_dirs to be a resource-hog when system is otherwise occupied.
# Version 2.0.2 - Fixed looping bash check in unRaid 6, plus fixed some too aggressive depth checks.
# Version 2.0.3 - Bugfix suspend mover, and added concise log of lost cache.
# Version 2.0.4 - Added more lost cache log, enabled by creating log file /var/log/cache_dirs_lost_cache.log
# Version 2.0.5 - Updated for unRaid 6.1.2 new location of mdcmd (used to find idle-times of disks)
# Version 2.0.6 - Included original 'B' option, it is unused but kept for compatibility reasons
#
# arberg
#
# Version 2.1.0 - Modified for unRaid V6.1 and above only.
#				- Removed V5 specific code.
#				- Removed disks busy code.
#				- Removed wait for array to come on line.
#				- Remove unused variables.
#				- Modifications to improve readability.
#
# Version 2.1.1	- Removed additional unused variables.
#				- Removed V5 ulimit usage info that doesn't apply.
#				- Show type of scanning being done - adaptive or fixed when cache_dirs is started.
#
# dlandon
####################################################################################
version=2.1.1
program_name=`basename $0`
program_dir=`dirname $0`
arg_count=$#

usage() {
	echo
	echo "Usage: $program_name [-m min_seconds] [-M max_seconds] [-F] [-d maxdepth(adaptive)] [-D maxdepth(fixed)] [-c command] [-a args] [-e exclude_dir] [-i include_dir]"
	echo "       $program_name -V      = print program version"
	echo "       $program_name -q"
	echo "       $program_name -l on   = turn on logging to /var/log/cache_dirs.log"
	echo "       $program_name -l off  = turn off logging to /var/log/cache_dirs.log"
	echo " -m NN    =   minimum seconds to wait between directory scans (default=1)"
	echo " -M NN    =   maximum seconds to wait between directory scans (default=10)"
	echo " -U NN    =   set ulimit to NN to limit memory used (default=50000), '-U 0' sets no ulimit at all)"
	echo " -F       =   do NOT run in background, run in Foreground and print statistics as it loops and scans"
	echo " -v       =   when used with -F, verbose statistics are printed as directories are scanned"
	echo " -s       =   shorter-log - print count of directories scanned to syslog instead of their names"
	echo " -d NN    =   max depth to allow when searching adaptively for appropriate depth level, used in \"find -maxdepth NN\" "
	echo " -D NN    =   sets fixed depth level and disables adaptive depth level, uses \"find -maxdepth NN\" "
	echo " -t NN    =   time in seconds between scheduled scan towards max depth, default weekly; this setting is only relevant with adaptive scan enabled (without -D setting)"
	echo " -c command = use command instead of \"find\" "
	echo "              ("command" should be quoted if it has embedded spaces)"
	echo " -a args  =   append args to command"
	echo " -u       =   also scan /mnt/user (scan user shares)"
	echo " -e exclude_dir  (may be repeated as many times as desired)"
	echo " -i include_dir  (may be repeated as many times as desired)"
	echo " -p NN    =   set cache_pressure to NN (by default = 10)"
	echo " -S       =   do not suspend scan during 'mover' process"
	echo " -z       =   concise log (log run criteria on one line)"
	echo " -q       =   terminate any background instance of cache_dirs"
}

background=yes
verbose=no
min_seconds=1
max_seconds=10
short_log=no
maxdepth=9999
fixdepth=-1
command="find"
window_array_length=20
avg_elapsed_time=0
exclude_array_count=0
include_array_count=0
quit_flag="no"
suspend_during_mover="yes"
commandargs=$*
user_share_dir=""
args="-noleaf"
concise_log="no"
run_log="/var/log/cache_dirs.log"
lost_cache_log="/var/log/cache_dirs_lost_cache.log"
scan_timeout_sec_initial=600
scan_timeout_sec_final=20
scan_judge_as_failure_sec=10
# Adaptively increase depth by 1 until depth_max_incremental_depth, then go to 9999
depth_max_incremental_depth=20
frequency_of_full_depth_scan_sec=$((7*24*3600))

ulimit_mem=50000

# Constants
NANO_PR_SEC=1000000000

# cache_pressure of 0 will potentially run out of RAM if a large directory is scanned and not enough RAM
# esists. User processes will then be killed to free space rather than cache freed.
# (It has happened several times on my server when I forgot to exclude my data folder.
# It is not fun trying to regain control without a full reboot.  I've changed the default to "1" instead. )
# If you have enough RAM, and few enough files being cached, you can specify "-p 0" on the command line
# to set the vfs_cache_pressure to 0.  Otherwise, this default value of 1 should prevent memory starvation
# and the OOM (out-of-memory) state killing on your processes to free up some RAM.
# 1 did not do it with my 500Meg of RAM... trying cache_pressure of 10, use -p 1 if you still want the old value
cache_pressure=10

verbose_echo() {
	[ $background = "no" -a $verbose = "yes" ] && echo $1
}

log() {
	[ $background = "no" -a $verbose = "yes" ] && echo $*
	[ "$run_log" != "" -a -f "$run_log" ] && echo $* >> $run_log
}

logLostCache() {
	if [ "$lost_cache_log" != "" -a -f "$lost_cache_log" ] ; then
		for var in "$@"
		do
			echo -n -e "$var\t"
		done >> $lost_cache_log
		echo >> $lost_cache_log
	fi
}

logLostCacheHeader() {
	if [ "$lost_cache_log" != "" -a -f "$lost_cache_log" ] ; then
		echo -e "Date\tTime\tScanTime\tPrevSleep\tIdleTimeBeforeScan\tDepth\tForcedRestartDepthScan" >> $lost_cache_log
	fi
}

syslog() {
	[ $background = "no" ] && echo $1
	[ "$run_log" != "" -a -f "$run_log" ] && echo $1 >> $run_log
	echo $1 | logger -t$program_name
}

while getopts ":p:m:M:Fvc:d:D:e:qi:szl:BbwuVa:SU:t:" opt; do
	case $opt in
	m ) min_seconds=$OPTARG ;;
	M ) max_seconds=$OPTARG ;;
	F ) background=no ;;
	v ) verbose=yes ;;
	V ) echo $program_name version: $version
	  exit 0 ;;
	u )  user_share_dir="/mnt/user" ;;
	c ) command="$OPTARG" ;;
	a ) args="$OPTARG" ;;
	d ) maxdepth=$OPTARG
	  command="find" ;;
	D ) fixdepth=$OPTARG
	  command="find" ;;
	i ) include_array[$include_array_count]="$OPTARG"
	  include_array_count=$(($include_array_count+1)) ;;
	e ) exclude_array[$exclude_array_count]="$OPTARG"
	  exclude_array_count=$(($exclude_array_count+1)) ;;
	h ) usage >&2 ; exit ;;
	p ) cache_pressure="$OPTARG" ;;
	U ) ulimit_mem="$OPTARG" ;;
	q ) quit_flag="yes" ;;
	w ) ;; # unused, kept for compatibility reasons
	s ) short_log="yes" ;;
	B ) ;; # unused, kept for compatibility reasons
	b ) ;; # unused, kept for compatibility reasons
	S ) suspend_during_mover="no" ;;
	z ) concise_log="yes" ;;
	t ) frequency_of_full_depth_scan_sec="$OPTARG" ;;
	l ) if [ "$arg_count" -ne 2 ] ; then
			echo "-l option may not be used in combination with others."
			echo "Usage:" >&2
			echo "cache_dirs -l on" >&2
			echo "or" >&2
			echo "cache_dirs -l off" >&2
			exit 2
		fi
		case "$OPTARG" in
		on)
			echo >$run_log
			echo "Logging enabled to $run_log"
			exit 0
		;;
		off)
			rm "$run_log"
			echo "Logging to $run_log stopped"
			exit 0
		;;
		*)
			echo "Invalid argument to -l option"
			echo "Usage:" >&2
			echo "cache_dirs -l on" >&2
			echo "or" >&2
			echo "cache_dirs -l off" >&2
			exit 2
		;;
		esac
	;;
	\?) usage >&2 ; exit ;;
	esac
done

#Try to play nice
if [ "$ulimit_mem" -gt 0 ] ; then
	log "Setting Memory ulimit to $ulimit_mem"
	ulimit -v $ulimit_mem
else
	log "No Memory ulimit applied"
fi

log "Setting maxdepth=$maxdepth"

lockfile="/var/lock/cache_dirs.LCK"
if [ -f "${lockfile}" ] ; then
	# The file exists so read the PID
	# to see if it is still running
	lock_pid=`head -n 1 "${lockfile}"`

	pid_running=`ps -p "${lock_pid}" | grep ${lock_pid}`

	if [ -z "${pid_running}" ] ; then
		if [ "$quit_flag" = "no" ] ; then
			# The process is not running
			# Echo current PID into lock file
			echo $$ > "${lockfile}"
		else
			echo "$program_name ${lock_pid} is not currently running "
			rm "${lockfile}"
			exit 0
		fi
	  else
		if [ "$quit_flag" = "yes" ] ; then
			syslog "Stopping $program_name process $lock_pid"
			# 1. Remove lock-file so we don't spawn new find-processes 2. kill current find-sub-process 3. Kill parent process
			rm "${lockfile}"
			pid_child=$(pgrep -P "$lock_pid")
			[ -n "${pid_child}" ] && kill "$pid_child"
			kill "$lock_pid"
			exit 0
		else
			echo "$program_name is already running [${lock_pid}]"
			exit 2
		fi
	  fi
else
	if [ "$quit_flag" = "yes" ] ; then
		echo "$program_name not currently running "
		exit 0
	else
		echo $$ > "${lockfile}"
	fi
fi

# validate the cache pressure
cc="$(echo $cache_pressure | sed 's/[0-9]//g')"
if [ ! -z "$cc" ] ; then
	echo "error: cache_pressure must be numeric." >&2
	usage >&2
	exit 2
fi

# validate the min number of seconds
cc="$(echo $min_seconds | sed 's/[0-9]//g')"
if [ ! -z "$cc" ] ; then
	echo "error: min number of seconds must be numeric (whole number, not negative)." >&2
	usage >&2
	exit 2
fi

# validate the max number of seconds
cc="$(echo $max_seconds | sed 's/[0-9]//g')"
if [ ! -z "$cc" ] ; then
	echo "error: max number of seconds must be numeric." >&2
	usage >&2
	exit 2
fi
if [ $max_seconds -lt $min_seconds ] ; then
	echo "error: max number of seconds must be greater than or equal min number of seconds." >&2
	usage >&2
	exit 2
fi

# validate the maxdepth
cc="$(echo $maxdepth | sed 's/[0-9]//g')"
if [ ! -z "$cc" ] ; then
	echo "error: directory scan maxdepth must be numeric." >&2
	usage >&2
	exit 2
fi
cc="$(echo $frequency_of_full_depth_scan_sec | sed 's/[0-9]//g')"
if [ ! -z "$cc" ] ; then
	echo "error: scheduled rescan time must be numeric, with -t $frequency_of_full_depth_scan_sec" >&2
	usage >&2
	exit 2
fi

shift $(($OPTIND - 1))

# start out in the middle of the range allowed.
num_seconds=$((( $max_seconds + $min_seconds ) / 2 ))

log "Setting cache_pressure=$cache_pressure"
sysctl vm.vfs_cache_pressure=$cache_pressure >/dev/null 2>&1

fnc_time_since_last_disk_access() {
	# Check if the array is started
	time_since_last_disk_access_sec=9999
	if [ -d /mnt/disk1 ] ; then
		mdcmd_cmd=/usr/local/sbin/mdcmd

		# rdevLastIO will be non-zero if a disk is spinning, it will be the timestamp of last IO (in seconds since epoch)
		last=$($mdcmd_cmd status | grep -a rdevLastIO | grep -v '=0')
		time_since_last_disk_access_sec=$(echo $last | awk '{t=systime(); gsub("rdevLastIO..=",""); for(i = 1; i <= NF; i++) a[++y]=$i}END{c=asort(a); if (NF > 0) print t-a[NF]; else print 9999; }')

		# Code to log all disk ages
		# ages=$(echo $last | awk '{ t=systime(); for(i = 1; i <= NF; i++){ match($i, /rdevLastIO.([0-9]+)/, capgroups); gsub("rdevLastIO..=","", $i);  print capgroups[1] "=" t-$i } }') #print "diskage" i "=" t-$i
		# log "Ages: $ages"
	fi
}

sleepAndCheckAreDisksIdle() {
	sleep 5
	fnc_time_since_last_disk_access
	are_disks_idle=$((time_since_last_disk_access_sec >= 4))
}


do_deep_scan() {
	depth_num=$1
	scan_timout=$2
	depth_arg=""
	[ "$depth_num" -ne 9999 ] && depth_arg="-maxdepth $depth_num"
	scanned_depth_msg+=" depth $depth_num"
	is_last_depth_scan_timed_out=0
	scan_start=`date +%s%N`
	share_disks_scanned_cnt=0
	while read share_dir
	do
		for i in /mnt/disk* /mnt/cache $user_share_dir
		do
			# If the directory does not exist on this disk, don't do recursive "directory scan"
			[ ! -d "$i"/"$share_dir" ] && continue

			# if lockfile removed, then don't do new finds
			[ ! -f "$lockfile" ] && continue
			(( is_last_depth_scan_timed_out )) && continue

			current_time_nano=`date +%s%N`
			# +1 to timeout because this is an integer computation
			remaining_time=$(( ((scan_timout+1)*NANO_PR_SEC-(current_time_nano-scan_start) ) / NANO_PR_SEC ))
			timepassed=$(( (current_time_nano-scan_start) / NANO_PR_SEC ))

			exitstatus=0
			# Perform a recursive "find" on /mnt/disk??/share, or /mnt/user/share, or /mnt/cache/share
			if (( remaining_time > 0 )) ; then
				((share_disks_scanned_cnt++))
				if [ -f /bin/timeout ] ; then
					# Stop scan after n seconds. Should actually decrease wait-duration based on previous shares scan-time
					/bin/timeout $remaining_time $command "$i"/"$share_dir" $args $depth_arg >/dev/null 2>&1
				else
					$command "$i"/"$share_dir" $args $depth_arg >/dev/null 2>&1
				fi
				exitstatus=$?
			else
				is_last_depth_scan_timed_out=1
				scanned_depth_msg+="(timeout ${scan_timout}s)"
			fi
			if [ $exitstatus -ne 0 ] ; then
				is_last_depth_scan_timed_out=1
				scanned_depth_msg+="(timeout ${scan_timout}s:Error=$exitstatus)"
			fi
			verbose_echo "$start_time_txt Executing $command $i/$share_dir $args $depth_arg"
		done
	done < <(echo "$dir_list")
}

build_dir_list() {
	# build a list of directories to cache.
	#   If no "-i" options are given, this will be all the top level directories in /mnt/disk* and /mnt/cache
	#   If "-i" entries are given, they will be the only top level dirs cached.
	#   If "-e" (exclude) directories are given, they are then deleted from the list by the comm -23 coommand.
	if [ $include_array_count -gt 0 ] ; then
		top_dirs=`(
		# Include designated directories
		a=0
		while test $a -lt $include_array_count
		do
			included_excl=$(find /mnt/disk* /mnt/cache -type d -maxdepth 1 -mindepth 1 -name "${include_array[$a]}" -exec basename {} \; 2>/dev/null)
			echo "$included_excl" | sort -u
			a=$(($a+1))
		done
		)| sort -u`
	else
		top_dirs=`find /mnt/disk* /mnt/cache -type d -maxdepth 1 -mindepth 1  -exec basename {} \; 2>/dev/null|sort -u`
	fi
	exclude_dirs=`(
		# Exclude designated directories from being processed
		a=0
		while test $a -lt $exclude_array_count
		do
			expanded_excl=$(find /mnt/disk* /mnt/cache -type d -maxdepth 1 -mindepth 1 -name "${exclude_array[$a]}" -exec basename {} \; 2>/dev/null)
			echo "$expanded_excl" | sort -u
			a=$(($a+1))
		done
	)| sort -u`
	scan_dirs=`comm -23 <(echo "$top_dirs") <(echo "$exclude_dirs")`
	echo "$scan_dirs"
}

function join { local IFS="$1"; shift; echo "$*"; }

dir_list=`build_dir_list`

if [ "$short_log" = "no" ] ; then
	log_list="$dir_list"
else
	log_list=$(echo "$dir_list" | wc -l)
	log_list=$(echo $log_list " directories cached")
fi

if ((fixdepth == -1)) ; then
	scan_type="adaptive"
	scan_depth=$maxdepth
else
	scan_type="fixed"
	scan_depth=$fixdepth
fi

if ((scan_depth == 9999)) ; then
	scan_depth="none"
fi

if [ "$concise_log" = "no" ] ; then
	echo "==============================================" | logger -t$program_name
	echo "Starting $program_name:" | logger -t$program_name
	echo "Arguments=$commandargs" | logger -t$program_name
	echo "Cache Pressure=$cache_pressure" | logger -t$program_name
	echo "Max Scan Secs=$max_seconds, Min Scan Secs=$min_seconds" | logger -t$program_name
	echo "Scan Type=$scan_type" | logger -t$program_name
	echo "Max Scan Depth=$scan_depth" | logger -t$program_name
	echo "Use Command='$command $args'" | logger -t$program_name
	echo "Version=$version" | logger -t$program_name
	echo "---------- Caching Directories ---------------" | logger -t$program_name
	echo "$log_list" | logger -t$program_name
	echo "----------------------------------------------" | logger -t$program_name
else
	echo "Arguments=$commandargs, Version=$version, Cache Pressure=$cache_pressure, Max Scan Secs=$max_seconds, Min Scan Secs=$min_seconds, Scan Type=$scan_type, Max Depth=$scan_depth, Use Command='$command $args'" | paste -s -d "," - | logger -t$program_name
	echo "$log_list" | paste -s -d "," - | logger -t$program_name
fi
log "Setting Included dirs $(join , ${include_array[@]})"
log "Setting Excluded dirs $(join , ${exclude_array[@]})"
log "command-args=$commandargs"

logLostCacheHeader

a=0
while test $a -lt $exclude_array_count
do
	list=`eval ls /mnt/disk*/"${exclude_array[$a]}" /mnt/cache/"${exclude_array[$a]}" 2>/dev/null`
	if [ "$list" = "" ] ; then
		echo "ERROR: excluded directory \"${exclude_array[$a]}\" does not exist." >&2
		echo "ERROR: excluded directory \"${exclude_array[$a]}\" does not exist." | logger -t$program_name
	fi
	a=$(($a+1))
done

a=0
while test $a -lt $include_array_count
do
	list=`eval ls /mnt/disk*/"${include_array[$a]}" /mnt/cache/"${include_array[$a]}" 2>/dev/null`
	if [ "$list" = "" ] ; then
		echo "ERROR: included directory \"${include_array[$a]}\" does not exist." >&2
		echo "ERROR: included directory \"${include_array[$a]}\" does not exist." | logger -t$program_name
	fi
	a=$(($a+1))
done

# Internal vars
depth_success_idle_incr_counter=0
depth_success_busy_incr_counter=0
depth_failure_incr_counter=0
if ((fixdepth >= 0)) ; then
	applieddepth=$fixdepth
	maxdepth=$fixdepth
	is_stable_depth_reached=1
	scan_timeout_sec=${scan_timeout_sec_final}
else
	applieddepth=0
	scan_timeout_sec=${scan_timeout_sec_initial}
	is_stable_depth_reached=0
fi

appliedmaxdepth=$maxdepth
last_scan_towards_max_depth=$(date +%s)

# max allowed scans with disk-access before we stop/decrease depth
max_no_disk_access_scans=3
while [ -f "$lockfile" ]
do
	is_last_depth_scan_timed_out=0
	if [ "$suspend_during_mover" = "yes" ] ; then
		if [ -f /var/run/mover.pid ] ; then
			if ps h `cat /var/run/mover.pid` | grep mover >/dev/null 2>&1 ; then
				log "Suspended during moving, now sleeping 10 seconds"
				sleep 10
				continue
			fi
		fi
	fi

	start_time_nano=`date +%s%N`
	start_time_txt=`date "+%Y.%m.%d %H:%M:%S"`

	fnc_time_since_last_disk_access
	time_since_disk_access_before_scan_sec=${time_since_last_disk_access_sec}

	# always cache root dirs on each of the disks
	for i in /mnt/disk* /mnt/cache $user_share_dir
	do
		find $i -maxdepth 1 -noleaf >/dev/null 2>/dev/null
	done

	scanned_depth_msg=""

	############## Here the actual find is executed ################
	do_deep_scan $applieddepth $scan_timeout_sec
	# I tried rescan at lower depth if scan timed out, but it hurt cache, some depth levels were unattainable with the lower depth scan enabled, they must have evicted higher depth cache for some reason

	fnc_time_since_last_disk_access
	time_since_disk_access_after_scan_sec=${time_since_last_disk_access_sec}

	end_time_nano=`date +%s%N`

	# track how long the recursive "directory scan" is taking.  If it starts to take longer it must be
	# because it has to read more from the physical disk.  If so, adjust the timing to
	# perform the directory scan more frequently.
	elapsed_time=$(( end_time_nano-start_time_nano ))
	elapsed_secs=$(( elapsed_time/NANO_PR_SEC ))
	were_disks_idle_during_scan=$((time_since_disk_access_after_scan_sec>=elapsed_secs))

	# Only update avg scan time when disks were idle during scan. This gives us ability to judge whether disks were accessed due to cache_dirs scan even if other processes access disks
	if (( were_disks_idle_during_scan )) ; then
		alen=${#avg[@]}
		# Move all the counts up one position in the array.
		for (( i = $(($alen)) ; i > 0 ; i-- ))
		do
			[ $i -lt $window_array_length ] && avg[$(($i+1))]=${avg[$i]}
		done

		# The newest will always be stored at index 1
		avg[1]=$elapsed_time

		# get the weighted average of the last $window_array_length loop passes
		# more recent values count far more than older values.
		tot_time=0
		alen=${#avg[@]}

		tot_count=0
		for (( i = 1; i <= $alen; i++ ))
		do
			weight=$(( $alen - $i + 1 ))
			weight=$(( $weight * 3 ))
			tot_count=$(( $tot_count + $weight))
			tot_time=$(( $tot_time + $(( ${avg[$i]} * $weight ))))
		done
		avg_elapsed_time=$(($tot_time/$tot_count))
	fi

	[ $avg_elapsed_time -eq 0 ] && avg_elapsed_time=$elapsed_time

	# Only decrease sleep when non-idle scan
	((were_disks_idle_during_scan)) && [ $avg_elapsed_time -lt $(($elapsed_time+100000)) -a $num_seconds -gt $min_seconds ] && num_seconds=$(($num_seconds-1))
	[ $avg_elapsed_time -gt $(($elapsed_time-100000)) -a $num_seconds -lt $max_seconds ] && num_seconds=$(($num_seconds+1))

	avg_elapsed_secs=$(( $avg_elapsed_time/1000000000 ))

	log_disk_access_msg=""

	do_sleep_until_disks_idle=0
	current_time_sec=$(date +%s)
	skip_sleep=0
	if ((fixdepth == -1)) ; then
		# Judge last scan based on duration and timeout: Increment success or failure counters
		if ((were_disks_idle_during_scan)) ; then
			log_disk_access_msg="Idle____________"
			((depth_success_idle_incr_counter++))
			depth_failure_incr_counter=0
		elif ((elapsed_secs < scan_judge_as_failure_sec && ! is_last_depth_scan_timed_out )) ; then
			# build cache-pressure by repeating successfull search, and give time for checking for disk-access
			if (( elapsed_time <= avg_elapsed_time + 2*NANO_PR_SEC )) ; then
				# depth_failure_incr_counter because we suspect its a scan which didn't access disks, since scan time was as fast as usual.
				depth_failure_incr_counter=0
				log_disk_access_msg="NonIdleUsualTime"
			else
				log_disk_access_msg="NonIdleSlowerAvg"
			fi
			((depth_success_busy_incr_counter++))
		else
			log_disk_access_msg="NonIdleTooSlow__"
			# Alex clean up (bug here? hence the log)
			log "Idle (or unknown): $elapsed_secs < $scan_judge_as_failure_sec && ! $is_last_depth_scan_timed_out || $time_since_disk_access_after_scan_sec>=$elapsed_secs"
			logLostCache $start_time_txt ${elapsed_secs} ${prev_sleep_duration} ${time_since_disk_access_before_scan_sec} $depth_num 0
			# timeout
			((depth_failure_incr_counter++))
			depth_success_idle_incr_counter=0
			depth_success_busy_incr_counter=0
			skip_sleep=1
		fi

		# Now increment or decrement depth level based on counters
		if ((applieddepth < appliedmaxdepth && (depth_success_idle_incr_counter>=3 || is_stable_depth_reached && depth_success_idle_incr_counter>=1 || depth_success_busy_incr_counter > 50) )) ; then
			# Increment depth
			(( applieddepth++ ))
			depth_failure_incr_counter=0
			depth_success_idle_incr_counter=0
			depth_success_busy_incr_counter=0
			# skip straight to 9999 if deep enough, so we can start sleeping
			(( applieddepth > depth_max_incremental_depth )) && applieddepth=$maxdepth
			if (( applieddepth >= appliedmaxdepth )) ; then
				is_stable_depth_reached=1
				scan_timeout_sec=${scan_timeout_sec_final}
			fi
		elif ((depth_failure_incr_counter >= max_no_disk_access_scans && applieddepth > 0)) ; then
			depth_failure_incr_counter=0
			depth_success_idle_incr_counter=0
			depth_success_busy_incr_counter=0
			if (( is_stable_depth_reached )) ; then
				# Reset depth to 1: It will only increase again once we have enough idle with successive scans
				do_sleep_until_disks_idle=1
				scan_timeout_sec=${scan_timeout_sec_initial}
				applieddepth=1
			# fi
			else
				# Decrement max depth, because we were finding the possible stable level, so we now set the appliedmaxdepth which acts as our upper bound
				(( applieddepth == 9999)) && appliedmaxdepth=$depth_max_incremental_depth || appliedmaxdepth=$((applieddepth-1))
				applieddepth=$appliedmaxdepth
				is_stable_depth_reached=1
				scan_timeout_sec=${scan_timeout_sec_final}
				log "Stopping at/decreasing to depth $appliedmaxdepth because previous scans have accessed disks/taken too long, will retry in $decreased_max_depth_rescan_wait_duration_sec secs"
		 	fi
		fi

		# Weekly full scan: In case of reduced max depth, test if we should reset and try going deeper again
		if ((current_time_sec > last_scan_towards_max_depth + frequency_of_full_depth_scan_sec)) ; then
			last_scan_towards_max_depth=$current_time
			if (( appliedmaxdepth < maxdepth )) ; then
				log "Starting scheduled depth scan again after waiting ${frequency_of_full_depth_scan_sec}s"
				appliedmaxdepth=$maxdepth
				is_stable_depth_reached=0
				scan_timeout_sec=${scan_timeout_sec_initial}
			fi
		fi
	fi

	# Alex changed logging for applied depth and no sleep
	# log duration
	if [ "$background" = "no" -o "$run_log" != "" ] ; then
		a=`awk "BEGIN{ printf \\"%05.2fs, wavg=%05.2fs\n\\", ($elapsed_time/1000000000), ($avg_elapsed_time/1000000000) ; }"`
	fi
	fnc_time_since_last_disk_access
	((applieddepth == appliedmaxdepth)) && next_sleep_duration=$num_seconds || next_sleep_duration=1
	#shareDirs scanned $share_disks_scanned_cnt
	log "$start_time_txt Executed $command in (${elapsed_secs}s) ${a}, find_timeout=${is_last_depth_scan_timed_out} ${log_disk_access_msg}, $scanned_depth_msg, sleep ${next_sleep_duration}s, Disks idle before/after ${time_since_disk_access_before_scan_sec}s/${time_since_disk_access_after_scan_sec}s, suc/fail cnt=${depth_success_idle_incr_counter}/${depth_failure_incr_counter}, scan_tmo=${scan_timeout_sec}s max=$appliedmaxdepth stable=$is_stable_depth_reached"

	if ((do_sleep_until_disks_idle)) ; then
		log "Pause until disks are idle again"
		logLostCache $start_time_txt ${elapsed_secs} ${prev_sleep_duration} ${time_since_disk_access_before_scan_sec} $depth_num 1
		sleepAndCheckAreDisksIdle
		while ((!are_disks_idle)); do
		  sleepAndCheckAreDisksIdle
		done
		log "Disks are idle again, so allow more time for disk-scans to regain desired depth level scan_timeout_sec ${scan_timeout_sec} -> ${scan_timeout_sec_initial}"
		do_sleep_until_disks_idle=0
	elif ((!skip_sleep)) ; then
		sleep ${next_sleep_duration}
	fi
	prev_sleep_duration=$next_sleep_duration
done &


# while loop was put into background, now disown it
# so it will continue to run when you log off
# to get it to stop, type: rm /var/lock/cache_dirs.LCK
background_pid=$!
echo $background_pid > "${lockfile}"
if [ $background = "no" ] ; then
	# only way to get here is to remove the lock file or kill the background process shell with the while loop
	trap "rm -f $lockfile; kill $background_pid 2>/dev/null; exit" INT TERM EXIT
	wait
else
	echo "$program_name process ID $background_pid started" >&2
	echo "$program_name process ID $background_pid started" | logger -t$program_name
	disown %%
fi
